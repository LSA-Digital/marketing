## LSA Digital — Marketing Campaign Organizing Doc (Feb 2026)

### Purpose
Generate interest from **business + technical audiences** in the LSA Digital brand, and convert that interest into **qualified conversations** that lead to **custom Human‑AI solution development** work.

### Principles:  North Star positioning (rebrand anchor)
- **Core thesis**: **Enterprise Heritage. Startup Velocity.**
- **Operating model**: Human‑AI **Develop → Deploy → Disrupt** concept-to-scale cycle.
- **Differentiator**: aim for speed **and** compliance/scale (the “LSA Zone”), not “fast prototypes that die in governance.”
- **Experience first** Everything must show experience to differentiate from “armchair quarterbacks”  who post stuff but haven’t actually done this before
- **Dual audiences** Must differentiate between tech / business audiences 

Primary sources for high-level LSA Digital & product messaging
- `https://www.lsadigital.com/`
- `https://www.lsadigital.com/products`

### Constraints
- **Low budget**: rely on partner reposts, founder networks, and repurposing one artifact into many formats.
- **Show evidence**: when practical, use real artifacts (screenshots, demo clips, architectures, tests, validation, workflow steps) first; “lessons learned” second.

---

## Audience map (write for both without sounding split-brained)
### Business readers
Founders, GMs, ops leaders, innovation leaders, VPs/Directors, program owners.
- Want: credible speed, reduced risk, clear pilot path, stakeholder-ready narrative.

### Technical readers
Enterprise architects, eng leads, platform teams, AI/ML leads, security/compliance, product managers.
- Want: architecture clarity, integration realities, auditability, evaluation/testing evidence.

---

## Offer + conversion path (keep it simple)
- **Primary CTA**: “Book a 20–30 min working session” (map your idea to Develop/Deploy/Disrupt + pilot path).
- **Secondary CTA**: “Request a demo” (LSARS / HSRA / EPMS / ReimagineIt / MEDICODA).
- **Proof CTA**: “See the artifacts” (short clips + screenshots + brief technical notes).

---

### Messaging Themes (tags)

see @messagingThemes.md for more granular messaging themes.  These can be tagged per-post.  They are more narrow than "Content Pillars" below.

---

## Content pillars 

### Pillar 1 — Experts + AI (Human‑in‑the‑Loop done for real)

Objective:  Attract pilot projects and/or investors for major solutions (especially HSRA, LSARS, MEDICODAX)
**Message**: AI accelerates; experts provide judgment + safety. We design workflows where **AI proposes and experts dispose**.

Anchor partnership/proof:
- LSARS principals on `https://lsars.com/`:
  - **Nelson Smith** (Principal; 35+ yrs environmental & legal / mass tort)
  - **Dr. Thad Perry** (Principal; 30+ yrs healthcare informatics & research; backed by clinical experts)
  - **Mike Idengren** (Principal; 28+ yrs digital transformation + AI tech; Human‑AI.com founder)

Products to spotlight under this theme:
- **LSARS** (expert verification + permitting/compliance workflows): `https://www.lsadigital.com/products/lsars` and `https://lsars.com/`
- **HSRA** (regulatory-grade health & social risk analysis; validated parity): `https://www.lsadigital.com/products/hra`
- **MEDICODAX** (coding force-multiplier; clinics + SLMs): `https://www.lsadigital.com/products/medicoda`

High-performing formats:
- "Before → after" workflow screenshots
- Expert review/verification step (what is checked, how, and why)
- Validation/evidence posts (parity, tests, E2E, audit trail)

### Pillar 2 — Vibe Engineering (Vibe Coding + Production-Grade Engineering)

**Objective**: Get more software development contracts by proving we can explore and prototype at maximum speed (vibe coding) *and* ship reliable, secure, scalable systems when the idea proves feasible.
**Message**: Most ideas are infeasible. Vibe coding is powerful because it helps you test assumptions fast and stop early.

Our differentiator is **the balance**: we treat "vibe" and "engineering" as a dial that shifts as risk increases.
- Early: move fast, generate options, validate feasibility, keep claims bounded.
- Later: add the receipts that make it production-ready (evals, observability, governance hooks, security boundaries, release gates).
- Heuristic: if it touches real users, real data, or real money, the dial moves toward engineering (and we can show exactly what changed).
- Human-UX (HUX) + Agent-UX (AUX): we are formalizing this because good Agent-UX (AUX) enables agents to use tools/APIs predictably, which improves Human-UX (HUX) for developers, which results in higher quality and faster product delivery.


**Products to spotlight under this theme:**
- **LSARS** (expert verification + permitting/compliance workflows): `https://www.lsadigital.com/products/lsars` and `https://lsars.com/`
- **HSRA** (regulatory-grade health & social risk analysis; validated parity): `https://www.lsadigital.com/products/hra`
- **EPMS** (AI-assisted product management + evidence + artifacts): `https://www.lsadigital.com/products/epms`
- **MEDICODAX** (coding force-multiplier; clinics + SLMs): `https://www.lsadigital.com/products/medicoda`


**Anchor proof:**
- Human‑in‑the‑Loop outreach system webinar recap: `https://www.lsadigital.com/insights/how-we-built-a-human-in-the-loop-ai-system-webinar-recap`
  - Includes: GQM method, agentic architecture, integrations (GPT‑4o, Apify, Tavily, Google CSE), closed feedback loop demo.

**High-performing formats:**
- Simple architecture diagrams (roles → agents → tools → data → governance)
- “How we evaluated it” (tests, parity checks, regression harness, E2E)
- “How humans steer it” (intent capture, review queues, audit logs, approvals)

How we will do it: Show the dial in action, with concrete artifacts at each stage, so "fast" doesn't mean "fragile".

Language note (external): we use **Vibe Engineering** on purpose, but we define it every time: vibe coding for exploration + production-grade engineering for shipping.

**Branding on marketing materials**

* LSA Digital logo
* Relevant product "spotlight"
* Make clear if it is business / tech audience 

---
**Initial post article synopses**

Approval tracking: check the box when a synopsis is approved for a full post write.

- [x] #FUTUREAI_PRODDEV, #AGENTICAI_DEVOPS, #TECH_UX - [PRODUCTS: EPMS] - EPMS has an MCP server for a specific reason: design Human-UX (HUX) and Agent-UX (AUX) together from day 0 (not bolted-on tooling).
  - Detail (use in post): EPMS has MCP server, for a specific reason:  product managers want to use the AI , but developers will have agents that need to interface at api layer.  This is what we mean by AGENTICAI_DEVOPS:  solutions must be built from the ground up to deliver an optimal User Experience and Agent User experience, not just "bolting on" a subset of MCP features (which is what we see now, even with major vendors - such as atlassian - MANY functions are missing)
  - Terminology: "User Experience" = Human-UX (HUX); "Agent User experience" = Agent-UX (AUX).

- [x] #TECH_UX, #AGENTICAI_DEVOPS, #FUTUREAI_PRODDEV - Human-UX (HUX) vs Agent-UX (AUX): what they mean, why we now use them together, and how they power a fast yet high-quality DevOps CE/CI/CD cycle.
  - Definitions: CE/CI/CD = Continuous Exploration / Continuous Integration / Continuous Deployment.
  - Note (use in post): Deployment is not the same as delivery/release to end users; product decides if/when and to which users deployed code is exposed.
  - Core idea: great Agent-UX (AUX) reduces tool friction and failure modes, which improves Human-UX (HUX) for developers and operators.
  - Payoff: tighter iteration loops + fewer regressions because the agent workflow is designed, tested, and observable (not improvised).

- [x] #AGENTICAI_DEVOPS, #TECH_SECURITY - [PRODUCTS: MEDICODAX] - Architecture and scalability proven with secure JWT tokens + multiple EHR integrations.
  - Detail (use in post): architecture and scalability proven with MEDICODAX secure jwt tokens & interface with multiple EHRs

- [x] #AGENTICAI_FIRST [PRODUCTS: MEDICODAX] - Dynamic AI workflow: process optimization for ground conditions (capture mode changes the whole loop).
  - Detail (use in post): Dynamic AI workflow - process optimization for ground conditions, e.g., are we capturing physician notes with iPhone or direct entry?  If iphone voice capture, AI agent scans notes and checks system to see if documentation matches the physician notes intent; if not, alerts pushed for staff to make sure documentation gets done in specific time frame

- [x] #FUTUREAI_PRODDEV [PRODUCTS: EPMS] - Investor / product management portal as a living artifact system + real-time Q&A.
  - Detail (use in post): Investor / product management portal stores markdown documents, live spreadsheets, videos, infographics, slide decks to describe the product as it is evoloved.  AI Chatbot answers questions in real time using the data compiled:  what are the ideas ?  What are the product value proposition KPIs and what solution features should be prioritized to hit them?  What’s the most important messaging ?  What is the financial impact, and is it feasible?

- [x] #FUTUREAI_PRODDEV, #AGENTICAI_DEVOPS - [PRODUCTS: EPMS] - The Vibe Engineering dial mapped to CE/CI/CD (Continuous Exploration / Continuous Integration / Continuous Deployment): CE naturally lives at 80/20 or 60/40 vibe/engineering; CI/CD pulls you toward 40/60 and 20/80 as risk increases.
  - Detail (use in post): The rapid AI-Assisted product lifecycle: It starts with an idea, and people research in ChatGPT naturally conversation, and use MCP to inteface with EPMS. PRODUCT ITERATION 1 - [80% vibe/20% engineer] developers create "skin-deep" mockups & UI demos.  PRODUCT IERATION 2 - [60% vibe/40% engineer] these get sharpened with product management & stakeholders into a prototype ; ITERATION 3 - [40% vibe/60% engineer] MVP funded for pilot; note that any technology usage with production users/data must have day0-pilot release security/compliance assured; ITERATION 4 - [20% vibe/80% engineer] pivot from pilot lessons learned; scale up
  - Alignment (use in post): CE = Continuous Exploration (80/20, 60/40). CI/CD = Continuous Integration / Continuous Deployment (40/60 or 20/80 depending on product maturity).
  - Note (use in post): Deployment is not the same as delivery/release; product controls release timing and audience (e.g., flags, staged rollout).

- [x] #FUTUREAI_PRODDEV, #AGENTICAI_DEVOPS - Real-time development & product management alignment: why we cannot just "vibe" everything.
  - Detail (use in post): Real-time development & product management alignment means we cannot just "vibe" everything; Even in 60% vibe mode, Jira tickets and lightweight planning docs should be created for every user story. We use claude/opencode commands to automate this, reinforced with hooks to make sure plans are created and updated to standards (for example, playwright screenshot evidence is required for any UI tickets).  Plan markdown docs are stored locally, and they reference jira ticket numbers; Jira tickets contain high-level information and status updates; local repo plan is more detailed for agent to rapidly revise with A/C.  for auto plan updates - keep Jira tickets in sync with the system build priorities and commits

- [x] #AGENTICAI_DEVOPS - Architecture planning documents: recommended at 40% engineer balance, required at 60%.
  - Detail (use in post): Architecture planning documents are recommended at 40% engineer balance, and required at 60%.  They provide guidance for both AI agents and humans by outlining key technology, components, security, data, interface and high-level compliance frameworks.  They should be "just-enough", and "enough" grows as the vibe engineering balance shifts more towards engineering and less vibing.  As needed, supplementary compliance, business process, and other relevant system-level documentation will be helpful to guide agents.  Tech debt guidance include weekly architecture/system design doc sweeps and re-optimization of AGENTS.md, commands, skills, and other agent guidance docs (these tend to get bloated as agents "tack more stuff on" during the heat of vibe engineering).

- [x] #AGENTICAI_DEVOPS - MCP proxy for lightweight context window management.
  - Detail (use in post): use MCP proxy for lightweight context window mgt (now built in with some products like claude)

- [x] #AGENTICAI_DEVOPS, #AGENTICAI_FIRST - Agent/tool diversity: get out of your comfort zone (Cursor, Claude, ChatGPT Codex) + open-source agents (OpenCode / kimi code).
  - Detail (use in post): Get out of your comfort zone (e.g., Cursor, Claude, ChatGPT Codex), and try open-source tools such as opencode / kimi code for agent diversity and faster features; for example, opencode will frequently include fast tab-switching to new, day-0 frontier-challenging models (e.g., Kimi K2.5 recently) that are incredibly cheap, fast, and frequently "almost" as good (good enough?) as much more expensive frontier models (Opus, ChatGPT Codex).

- [x] #FUTUREAI_DEVOPS - Humans expect answers. Agents need the same inside the dev environment when context compresses.
  - Detail (use in post): Humans use AI to ask questions and expect relevant answers in return.  AI Agents need to do the same thing in your dev environment, EVERY time the context window is compressed.  Cursor has tools built int o allow this, but we have created the same capability  with open-source tools such as graph-code and memgraph, representing our code base in vector space (Qdrant)

- [x] #FUTUREAI_PRODDEV, #TECH_SECURITY - Safe sandbox tips.
  - Detail (use in post): safe sandbox tips

- [x] #FUTUREAI_PRODDEV - Managing context windows feels like managing 4MB of RAM in the 90’s.
  - Detail (use in post): managing context windows feels like managing 4MB of RAM in the 90’s

- [x] #TECH_SECURITY - Zero trust and reverse proxy example.
  - Detail (use in post): zero trust and reverse proxy example (leverage mike's post)

- [x] #AGENTICAI_FIRST - CONTEXT7! MUST HAVE!
  - Detail (use in post): Even today's most sophisticated models (Claude 4.6) still unnecessarily try to solve problems by themselves.

**Additional synopses (recommended to win dev contracts)**

- [x] #AGENTICAI_DEVOPS, #FUTUREAI_PRODDEV - The agent evaluation harness: why your AI demo fails in production, and how we build regression tests for tool-using workflows (golden tasks, mocks, model-change baselines, pass/fail thresholds).
- [x] #AGENTICAI_DEVOPS, #FUTUREAI_PRODDEV - Observability for agentic systems: tracing tool calls end-to-end (latency/cost budgets, retry reasons, error taxonomies) so teams can answer "why did it do that?" in minutes.
- [x] #AGENTICAI_DEVOPS, #TECH_SECURITY - Agent security threat model: prompt injection, tool authorization, least-privilege tokens, network egress control, and audit logs (what we enforce by architecture, not policy).
- [x] #TECH_UX, #AGENTICAI_FIRST - Human-in-the-loop UX patterns that scale: approval gates, review queues, escalation levels, and "safe defaults" that keep humans in control without becoming a bottleneck.
- [x] #AGENTICAI_DEVOPS - Prompt/config is infrastructure: versioning, code review, rollout/canaries, and “break-glass” rollback for agent behavior changes.
- [x] #FUTUREAI_PRODDEV, #AGENTICAI_DEVOPS - From prototype to pilot-ready in 2–4 weeks: the artifact pack we ship (architecture diagram, eval plan, security boundaries, runbook, demo script) and why it de-risks stakeholder buy-in.
- [x] #TECH_UX, #AGENTICAI_DEVOPS - Designing APIs for agents: idempotency, schema contracts, error messages that teach recovery, and why Agent-UX (AUX) is now a first-class product surface.
- [x] #TECH_SECURITY, #AGENTICAI_DEVOPS - Sandboxed tool execution in the real world: ephemeral credentials, scoped permissions, and per-tool policy enforcement (with an example policy and audit trail).

- [x] #TECH_SECURITY, #FUTUREAI_DEVOPS - Automated compliance: continuous control monitoring + evidence capture (we use Drata.com) so compliance doesn't become a quarterly scramble.
- [x] #TECH_SECURITY, #AGENTICAI_DEVOPS - Security bug evidence loop: any security bug requires documentation proving it was fixed (e.g., Jira ticket analysis + verification evidence), so audits are painless and engineering stays honest.

---

## Content rules (non‑negotiables)

Generally, **No AI slop**:  The content must feel authentic; no formulaic mechanical posts or recycled garbage.  It has to be anchored in real experience for real outcomes, including the domain expertise from real partners/experts when appropriate (e.g., business domain problem-solving posts).

- **Experience-first**: include at least one of (text description, screenshot, short clip, diagram, test/validation snippet) in every major post.
- **Then interpretation**: lessons learned, best practices derived from the experience.
- **No generic hype**: if it can be posted by any AI consultancy, it doesn’t ship.
- **Claims discipline**: keep stages accurate (DEVELOP/DEPLOY/public beta/in progress).

---

## Single source of truth: Expert ↔ product alignment
Maintain and reference:
- `./lsaProductExpertAlignment.md`

Writing agents must pull expert names/roles/claim boundaries from that file only.

---

## Content inventory (primary sources for agents)
Brand and portfolio:
- `https://www.lsadigital.com/`
- `https://www.lsadigital.com/products`

Products:
- LSARS: `https://www.lsadigital.com/products/lsars`
- HSRA: `https://www.lsadigital.com/products/hra`
- EPMS: `https://www.lsadigital.com/products/epms`
- MEDICODA: `https://www.lsadigital.com/products/medicoda`
- Human‑AI Concept Lab: `https://www.lsadigital.com/products/human-ai-optimizer`
- ReimagineIt: `https://www.lsadigital.com/products/reimagineit`

Proof / “what we built”:
- Webinar recap (Human‑in‑the‑Loop outreach system): `https://www.lsadigital.com/insights/how-we-built-a-human-in-the-loop-ai-system-webinar-recap`
- Partner site (bios + LSARS proof): `https://lsars.com/`

Note:
- There is also an LSA Digital insight post titled “LSA ProspectPilot Human‑AI Marketing Solution” listed on the LSA Digital homepage insights section. If used, link directly:
  - `https://www.lsadigital.com/insights/lsa-prospectpilot-human-ai-marketing-solution`

---

## Content creation standard (simple + durable)
### Rule: every post lives in `./posts/`
- **All post content goes in `posts/`** so it’s searchable, reusable, and easy to ship.
- **Each post gets its own sub-folder** under `posts/`.
- A “post” is defined by **one Markdown file** (the canonical post text) plus any supporting assets (images/video/etc).
- The Markdown file may include **local assets** and **remote links**:
  - **Local assets** (preferred for screenshots/exports you control) must live **in the same post folder** as the Markdown file.
  - **Remote links** are allowed for canonical sources (product pages, partner sites, YouTube, etc.).

### Recommended folder structure (stands the test of time)
Use a date + slug so posts naturally sort and are stable across weeks/months/years.

- `posts/YYYY/MM/YYYY-MM-DD_slug/`
  - `post.md` (canonical post text + notes)
  - `assets/` (optional; images, gifs, video, diagrams, exported PDFs)
  - `links.md` (optional; curated remote URLs, citations, UTMs)
  - `notes.md` (optional; research, SME feedback, approvals, claim boundaries)

Example:
- `posts/2026/02/2026-02-03_lsars-expert-verification/`
  - `post.md`
  - `assets/lsars_workflow_before_after.png`
  - `assets/outreach_loop.mp4`
  - `links.md`

### Post Markdown conventions (keep it lightweight)
At the top of `post.md`, include a small metadata block so it’s easy to plan and review:
- **Title**
- **Channel** (LinkedIn post | demo clip script | longer artifact)
- **Theme** (Experts+AI | AI technology | Compliance+scale)
- **Status** (draft | in_review | approved | published)
- **Publish target** (date + time + poster)
- **SME reviewer** (from `./lsaProductExpertAlignment.md` when relevant)
- **Artifacts** (local file paths + remote links)
- **Claim boundaries** (prototype / beta / in progress; “what we did” only)

---

## Distribution plan (low budget, partner-forward)
Primary channel:
- LinkedIn (company + founders/SMEs)

Partner amplification (make it easy):
- Build “repost kits” per post (3 suggested captions + 1 image + 3 bullets + 1 link with UTM).
- Tag partners/SMEs when relevant (pre-coordinate so it’s not a surprise).

Secondary (optional):
- YouTube shorts (unlisted clips embedded in posts)
- Newsletter repost (same content, different intro)
- Targeted community posts (product mgmt, enterprise architecture, compliance, environmental permitting)

Always:
- Use **UTMs** on outbound links (including partner repost kits).

---

## Publication cadence (Feb 2026 baseline)
Sustainable starter cadence:
- **3 LinkedIn posts/week** (**Mon + Wed + Fri**)
- **2 short demo clips/week** (recommend Tue + Thu)
- **1 longer artifact drop/week** (blog/insight-style post OR PDF “artifact drop”)

### Feb 2026 editorial calendar (starter)
Week 1
- **Mon post**: Theme 1: LSARS — expert verification workflow (“AI proposes; experts dispose”)
- **Tue clip**: Develop → Deploy → Disrupt in 60–90s using one product as example
- **Wed post**: Theme 2: Human‑in‑the‑Loop outreach system — architecture + why GQM worked
- **Thu clip**: Outreach system loop diagram + narration (60–90s)
- **Fri post**: Theme 3: Speed with compliance & scale — “what makes it enterprise-ready” checklist (artifact-first)
- **Longer artifact (weekly)**: 1–2 page “Artifact drop” PDF: outreach system architecture (roles → agents → tools → governance) + 3 key lessons

Week 2
- **Mon post**: Theme 1: HSRA — what “parity validated” means (explain simply + show evidence types)
- **Tue clip**: HSRA evidence types walkthrough (tests/parity/audit trail) in 60–90s (no over-claims)
- **Wed post**: Theme 2: ReimagineIt — clarity score prevents fast wrong solutions
- **Thu clip**: “Clarity score” demo snippet / storyboard (60–90s)
- **Fri post**: Theme 3: Speed with compliance & scale — how humans steer + approve (review queues + audit logs)
- **Longer artifact (weekly)**: Blog/insight-style post: “What parity validation means (and what it doesn’t)” + screenshots/artifacts

Week 3
- **Mon post**: Theme 1: MEDICODA — clinic partnership realities (burnout, accuracy, auditing)
- **Tue clip**: Human final decision loop + real-time auditing (60–90s)
- **Wed post**: Theme 2: EPMS — AI-assisted discovery while PM intent stays in control
- **Thu clip**: “From idea to pilot-ready” mapped to Develop/Deploy/Disrupt (60–90s; avoid over-claims)
- **Fri post**: Theme 2: EPMS — “artifact capture” mini-checklist (intent → tool calls → outputs → traceability)
- **Longer artifact (weekly)**: EPMS artifact drop: intent entry screenshot + example outputs + boundary/governance notes

Week 4
- **Mon post**: Theme 3: Speed vs compliance — practical checklist (auditability, tests, approvals)
- **Tue clip**: “What makes Human‑AI enterprise-ready?” (short, concrete; 60–90s)
- **Wed post**: Theme 1+2: LSARS unified platform story (trust + HSRA + AI tooling)
- **Thu clip**: LSARS workflow “before → after” (60–90s)
- **Fri post**: Theme 1: Experts + AI — how to request SME soundbites + review flow (lightweight process, artifact-first)
- **Longer artifact (weekly)**: End-of-month round-up: “Feb artifacts” gallery post (links + 1 paragraph per artifact)

---

## Brief template for content-writing agents (copy/paste)
- Audience: business / technical / mixed
- Theme: Experts+AI / AI technology / Compliance+scale
- Primary artifacts to cite: (paste 1–3 URLs)
- One concrete “what we did”: (screenshot? test? workflow? clip? architecture?)
- Claim boundaries: prototype vs public beta vs “in progress”
- CTA: demo request / working session / artifact download
- Format: LinkedIn short / LinkedIn long / carousel script / 60s clip script
- SME reviewer: (from `./lsaProductExpertAlignment.md`)

---

## Publishing checklist for publishing agents
- Visual attached (screenshot/clip/diagram)
- Hook is problem-first, not hype-first
- Includes one measurable detail (tests, parity, workflow step, time saved, accuracy target—only if provable)
- Partner repost kit prepared (3 alt captions)
- UTM link used
- Seed 2 comments (artifact detail + a question)

### UTM convention + repost kit template (low budget amplification)
#### UTM convention (simple, consistent)
Use:
- `utm_source`: linkedin | partner | newsletter | youtube
- `utm_medium`: organic | repost | comment
- `utm_campaign`: feb_2026_human_ai
- `utm_content`: short_slug_for_post (e.g., lsars_expert_verify_01)

#### Repost kit (paste into a shared doc/thread for partners)
- **Post link**: <URL with UTM>
- **1 image / 1 clip**: <asset link>
- **3 suggested captions**:
  1) (business-leaning) …
  2) (technical-leaning) …
  3) (partner voice) …
- **3 proof bullets (artifact-based)**:
  - …
  - …
  - …
- **1 question prompt** (to drive comments):
  - …

---

## KPI + feedback loop (minimal viable)
- Top-of-funnel: impressions, saves, meaningful comments, partner reposts
- Mid-funnel: clicks to demo/Let’s Talk, time on page
- Bottom-funnel: booked calls, pilot requests, intros

Every 2 weeks:
- Identify top 2 posts by saves/comments
- Publish “Part 2” deeper on one artifact (not broader)

---

## Additional planning angles (recommended)
- ICP slices + message matrix:
  - “Ops bottleneck” (ReimagineIt), “Permit risk” (LSARS/HSRA), “PM discovery speed” (EPMS), “Compliance-heavy workflow” (Human‑AI Concept Lab), “Clinical admin burden” (MEDICODA)
- Proof library:
  - “Artifact gallery” page: screenshots, short clips, diagrams, validation/testing evidence
- Objection handling posts:
  - “Is this secure?”, “How do we audit it?”, “What’s the human’s role?”, “What’s real vs prototype?”
- Partner-forward calendar:
  - 1–2 posts/month explicitly co-authored with partner SMEs (max repost leverage)
