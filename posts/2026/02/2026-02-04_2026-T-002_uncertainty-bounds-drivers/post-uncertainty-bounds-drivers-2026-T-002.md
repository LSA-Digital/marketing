# Stop shipping "confidence." Ship bounds + drivers.

## Metadata
- **Post ID**: 2026-T-002
- **CTA**: see artifacts at [lsadigital.com](https://lsadigital.com)
- **Depends on**: 2026-B-002 (permitability-score)

## Post

If a model can't tell you why a number moved, the number isn't "smart." It's dangerous.

We built uncertainty into the workflow on purpose: **bounds + drivers**, not false precision.

We applied this in LSARS permitting workflows—where timelines, investments, and trust all get punished when uncertainty is hidden.

Key supporting details:
- **Quantify uncertainty when it matters**: return a bounded estimate and the top drivers, not just a single score.
- **Keep answers auditable**: make it easy to see what evidence was used and what assumptions were applied.
- **Escalate safely**: keep the primary advisor read-only and only escalate to deeper research when governed context is insufficient.

Result: stakeholders get fewer surprises, engineering gets fewer "rewrite this for audit" cycles, and decisions get easier to defend.

If you want the approach and artifacts, start at [lsadigital.com](https://lsadigital.com).

## Artifacts
- Remote:
  - https://www.lsadigital.com/products/lsars

## Post asset ideas

### Missing assets (add before publish)

- [ ] Simple diagram: “single number” vs “bounds + drivers”
- [ ] Example “driver list” visual (top 3 drivers + short explanation)
- [ ] LSA Digital branded header image (optional)

### Notes

- Diagrams should be readable on mobile
- Keep it implementation-agnostic (pattern over stack)
